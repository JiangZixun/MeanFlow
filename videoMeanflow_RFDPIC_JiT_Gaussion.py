# videoMeanflow.py
import torch
import torch.nn.functional as F
from einops import rearrange
from functools import partial
import numpy as np


class Normalizer:
    # --- ä¿æŒä¸å˜ ---
    def __init__(self, mode='minmax', mean=None, std=None):
        assert mode in ['minmax', 'mean_std'], "mode must be 'minmax' or 'mean_std'"
        self.mode = mode
        if mode == 'mean_std':
            if mean is None or std is None:
                raise ValueError("mean and std must be provided for 'mean_std' mode")
            self.mean = torch.tensor(mean).view(1, 1, -1, 1, 1)
            self.std = torch.tensor(std).view(1, 1, -1, 1, 1)
    @classmethod
    def from_list(cls, config):
        mode, mean, std = config
        return cls(mode, mean, std)
    def norm(self, x):
        if self.mode == 'minmax':
            return x * 2 - 1
        elif self.mode == 'mean_std':
            return (x - self.mean.to(x.device)) / self.std.to(x.device)
    def unnorm(self, x):
        if self.mode == 'minmax':
            x = x.clip(-1, 1)
            return (x + 1) * 0.5
        elif self.mode == 'mean_std':
            return x * self.std.to(x.device) + self.mean.to(x.device)


def stopgrad(x):
    return x.detach()


def adaptive_l2_loss(error, gamma=0.5, c=1e-3):
    # --- ä¿æŒä¸å˜ ---
    delta_sq = torch.mean(error ** 2, dim=(1, 2, 3, 4), keepdim=False)
    p = 1.0 - gamma
    w = 1.0 / (delta_sq + c).pow(p)
    loss = delta_sq
    return (stopgrad(w) * loss).mean()


class MeanFlow:
    # --- __init__ ä¿æŒæ‚¨æä¾›çš„ç‰ˆæœ¬ä¸å˜ ---
    def __init__(
        self,
        channels=8,
        time_dim=6,
        height_dim=256,
        width_dim=256,
        num_classes=None, # åºŸå¼ƒ
        normalizer=['minmax', None, None],
        # mean flow settings
        flow_ratio=0.50,
        # time distribution, mu, sigma
        time_dist=['lognorm', -0.4, 1.0],
        cfg_ratio=0.10,
        # set scale as none to disable CFG distill
        cfg_scale=2.0,
        # experimental
        cfg_uncond='v',
        jvp_api='autograd',
    ):
        super().__init__()
        self.channels = channels
        self.time_dim = time_dim
        self.height_dim = height_dim
        self.width_dim = width_dim
        self.num_classes = num_classes 
        self.use_cond = True 

        self.normer = Normalizer.from_list(normalizer)
        self.flow_ratio = flow_ratio
        self.time_dist = time_dist
        self.cfg_ratio = cfg_ratio
        self.w = cfg_scale
        self.cfg_uncond = cfg_uncond
        self.jvp_api = jvp_api

        assert jvp_api in ['funtorch', 'autograd'], "jvp_api must be 'funtorch' or 'autograd'"
        if jvp_api == 'funtorch':
            self.jvp_fn = torch.func.jvp
            self.create_graph = False
        elif jvp_api == 'autograd':
            self.jvp_fn = torch.autograd.functional.jvp
            self.create_graph = True

    # sample_t_r (æ— ä¿®æ”¹)
    def sample_t_r(self, batch_size, device):
        if self.time_dist[0] == 'uniform':
            samples = np.random.rand(batch_size, 2).astype(np.float32)
        elif self.time_dist[0] == 'lognorm':
            mu, sigma = self.time_dist[-2], self.time_dist[-1]
            normal_samples = np.random.randn(batch_size, 2).astype(np.float32) * sigma + mu
            samples = 1 / (1 + np.exp(-normal_samples))  # Apply sigmoid
        t_np = np.maximum(samples[:, 0], samples[:, 1])
        r_np = np.minimum(samples[:, 0], samples[:, 1])
        num_selected = int(self.flow_ratio * batch_size)
        indices = np.random.permutation(batch_size)[:num_selected]
        r_np[indices] = t_np[indices]
        t = torch.tensor(t_np, device=device)
        r = torch.tensor(r_np, device=device)
        return t, r

    # def loss(self, model, x, c=None): # x=x_future
    #     """
    #     ğŸ”´ æ ¸å¿ƒä¿®æ”¹ï¼š
    #     c ä¸å†æ˜¯å•ä¸ªå¼ é‡ï¼Œè€Œæ˜¯ä¸€ä¸ªå…ƒç»„ (c_start, c_cond)
    #     c_start: æµçš„èµ·ç‚¹ (c_past)
    #     c_cond: æ¨¡å‹çš„æ¡ä»¶ (c_rfdpic)
    #     """
    #     if not isinstance(c, (tuple, list)) or len(c) != 2:
    #         raise ValueError("`c` must be a tuple `(c_start, c_cond)`."
    #                          " `c_start` is the past distribution (t=1), "
    #                          " `c_cond` is the external condition (e.g., RFDPIC pred).")
        
    #     c_start, c_cond = c
        
    #     # ç¡®ä¿ x å’Œ c_start å½¢çŠ¶ç›¸åŒ
    #     if x.shape != c_start.shape:
    #          raise ValueError(f"x (x_future) and c_start (c_past) must have the same shape. "
    #                          f"Got x: {x.shape} and c_start: {c_start.shape}")

    #     batch_size = x.shape[0]
    #     device = x.device

    #     t, r = self.sample_t_r(batch_size, device)
    #     t_ = rearrange(t, "b -> b 1 1 1 1").detach().clone()
    #     r_ = rearrange(r, "b -> b 1 1 1 1").detach().clone()

    #     # --- ğŸ”´ 1. ä¿®æ”¹ï¼šæµçš„èµ·ç‚¹ e æ˜¯ c_start (c_past) ---
    #     e = self.normer.norm(c_start) # å½’ä¸€åŒ– t=1 çš„ç‚¹
    #     x = self.normer.norm(x)       # å½’ä¸€åŒ– t=0 çš„ç‚¹ (x_future)

    #     z = (1 - t_) * x + t_ * e
    #     # --- ğŸ”´ 2. ä¿®æ”¹ï¼šv æ˜¯ä» x åˆ° e çš„é€Ÿåº¦ ---
    #     v = e - x
        
    #     # --- CFG é€»è¾‘ç°åœ¨ä½œç”¨äº c_cond (c_rfdpic) ---
    #     if c_cond is not None:
    #         assert self.cfg_ratio is not None
            
    #         # 'uncond' å¿…é¡»ä¸ c_cond (c_rfdpic) å½¢çŠ¶ç›¸åŒ
    #         uncond = torch.zeros_like(c_cond)
            
    #         cfg_mask = torch.rand(batch_size, device=device) < self.cfg_ratio
    #         cfg_mask_expanded = rearrange(cfg_mask, "b -> b 1 1 1 1")
            
    #         # c_cond_input æ˜¯ c_rfdpic å’Œ uncond (é›¶å¼ é‡) ä¹‹é—´çš„é€‰æ‹©
    #         c_cond_input = torch.where(cfg_mask_expanded, uncond, c_cond)
            
    #         if self.w is not None: # CFG è’¸é¦
    #             with torch.no_grad():
    #                 u_t = model(z, t, t, uncond)
    #             v_hat = self.w * v + (1 - self.w) * u_t
    #             if self.cfg_uncond == 'v':
    #                 cfg_mask_v = rearrange(cfg_mask, "b -> b 1 1 1 1").bool()
    #                 v_hat = torch.where(cfg_mask_v, v, v_hat)
    #         else:
    #             v_hat = v
    #     else:
    #         # å¦‚æœæ²¡æœ‰ c_cond (ä¾‹å¦‚ c_rfdpic=None)
    #         c_cond_input = None
    #         v_hat = v

    #     # forward pass
    #     # model_partial ä½¿ç”¨ c_cond_input (c_rfdpic æˆ– uncond) ä½œä¸ºæ¡ä»¶
    #     model_partial = partial(model, y=c_cond_input)
    #     jvp_args = (
    #         lambda z, t, r: model_partial(z, t, r),
    #         (z, t, r),
    #         (v_hat, torch.ones_like(t), torch.zeros_like(r)),
    #     )

    #     if self.create_graph:
    #         u, dudt = self.jvp_fn(*jvp_args, create_graph=True)
    #     else:
    #         u, dudt = self.jvp_fn(*jvp_args)

    #     u_tgt = v_hat - (t_ - r_) * dudt
    #     error = u - stopgrad(u_tgt)
    #     loss = adaptive_l2_loss(error)
    #     mse_val = (stopgrad(error) ** 2).mean()
        
    #     return loss, mse_val

    def loss(self, model, x, c=None): # x=x_future
        # ... (å‰åºæ£€æŸ¥å’Œ t, r é‡‡æ ·ä»£ç ä¿æŒä¸å˜) ...
        # ... (ç›´åˆ° defined e å’Œ z) ...

        if not isinstance(c, (tuple, list)) or len(c) != 2:
            raise ValueError("c must be (c_start, c_cond)")
        c_start, c_cond = c
        
        batch_size = x.shape[0]
        device = x.device

        t, r = self.sample_t_r(batch_size, device)

        t_ = rearrange(t, "b -> b 1 1 1 1").detach().clone()
        r_ = rearrange(r, "b -> b 1 1 1 1").detach().clone()

        e = torch.randn_like(x) # ğŸ”´ å°†èµ·ç‚¹ e è®¾ä¸ºæ ‡å‡†é«˜æ–¯å™ªå£°
        x = self.normer.norm(x)       

        z = (1 - t_) * x + t_ * e
        v = e - x # Ground Truth Velocity
        
        # --- ğŸ”´ æ ¸å¿ƒä¿®æ”¹å¼€å§‹: x-prediction è½¬æ¢ ---
        
        # å®šä¹‰ä¸€ä¸ª wrapperï¼Œå°†æ¨¡å‹è¾“å‡º(x)è½¬æ¢ä¸ºé€Ÿåº¦(v)
        # è¿™æ · jvp è®¡ç®—çš„å¯¼æ•°ä¹Ÿæ˜¯åŸºäº velocity çš„ï¼Œä¿æŒåŸæœ‰ä¸€è‡´æ€§
        def get_velocity_from_x_model(z_in, t_in, r_in, cond_in):
            # 1. æ¨¡å‹ç›´æ¥é¢„æµ‹å¹²å‡€çš„ x (Target) [cite: 11, 48]
            x_pred = model(z_in, t_in, r_in, cond_in)
            
            # 2. æ ¹æ®å…¬å¼ v = (z - x) / t å°† x è½¬æ¢ä¸º v
            #  è®ºæ–‡å»ºè®® clip åˆ†æ¯ä»¥é˜²æ­¢é™¤é›¶
            # æ³¨æ„ï¼šä½ çš„ä»£ç ä¸­ t=0 æ˜¯ cleanï¼Œæ‰€ä»¥åˆ†æ¯æ˜¯ t
            t_in_clamped = t_in.clamp(min=1e-3) 
            t_expand = rearrange(t_in_clamped, "b -> b 1 1 1 1")
            
            v_pred = (z_in - x_pred) / t_expand
            return v_pred

        # --- å¤„ç† CFG (åœ¨ Velocity ç©ºé—´è¿›è¡Œæ··åˆ) ---
        if c_cond is not None:
            assert self.cfg_ratio is not None
            uncond = torch.zeros_like(c_cond)
            cfg_mask = torch.rand(batch_size, device=device) < self.cfg_ratio
            cfg_mask_expanded = rearrange(cfg_mask, "b -> b 1 1 1 1")
            c_cond_input = torch.where(cfg_mask_expanded, uncond, c_cond)
            
            # è®¡ç®—ç›®æ ‡ v_hat (ç”¨äºè’¸é¦æˆ–ä½œä¸º jvp çš„ç›®æ ‡)
            if self.w is not None: 
                with torch.no_grad():
                    # è·å– unconditional çš„é€Ÿåº¦
                    v_uncond = get_velocity_from_x_model(z, t, t, uncond)
                
                # è¿™é‡Œ v æ˜¯ Ground Truthã€‚
                # å¦‚æœè¦åš CFG Distillï¼Œé€šå¸¸æ˜¯ mix(v_cond_pred, v_uncond_pred)
                # ä½†åŸä»£ç é€»è¾‘æ˜¯ mix(GT_v, Model_uncond_v)ã€‚ä¿æŒåŸé€»è¾‘ï¼š
                v_hat = self.w * v + (1 - self.w) * v_uncond
                
                if self.cfg_uncond == 'v':
                     cfg_mask_v = rearrange(cfg_mask, "b -> b 1 1 1 1").bool()
                     v_hat = torch.where(cfg_mask_v, v, v_hat)
            else:
                v_hat = v
        else:
            c_cond_input = None
            v_hat = v

        # --- JVP è®¡ç®— ---
        # å°† wrapper ä¼ å…¥ jvpï¼Œè€Œä¸æ˜¯åŸå§‹ model
        # è¿™æ · u å°±æ˜¯ velocity, dudt ä¹Ÿæ˜¯ velocity å¯¹æ—¶é—´çš„å¯¼æ•°
        model_partial_v = partial(get_velocity_from_x_model, cond_in=c_cond_input)
        
        jvp_args = (
            lambda z, t, r: model_partial_v(z, t, r),
            (z, t, r),
            (v_hat, torch.ones_like(t), torch.zeros_like(r)),
        )

        if self.create_graph:
            u, dudt = self.jvp_fn(*jvp_args, create_graph=True)
        else:
            u, dudt = self.jvp_fn(*jvp_args)

        u_tgt = v_hat - (t_ - r_) * dudt
        error = u - stopgrad(u_tgt)
        loss = adaptive_l2_loss(error)
        mse_val = (stopgrad(error) ** 2).mean()
        
        return loss, mse_val

    # @torch.no_grad()
    # def sample_prediction(self, model, c_past_and_cond, sample_steps=5, device='cuda'):
    #     """
    #     ğŸ”´ æ ¸å¿ƒä¿®æ”¹ï¼š
    #     c_past_and_cond æ˜¯ä¸€ä¸ªå…ƒç»„ (c_start, c_cond)
    #     c_start: æµçš„èµ·ç‚¹ (c_past)
    #     c_cond: æ¨¡å‹çš„æ¡ä»¶ (c_rfdpic)
    #     """
    #     if not isinstance(c_past_and_cond, (tuple, list)) or len(c_past_and_cond) != 2:
    #         raise ValueError("`c_past_and_cond` must be a tuple `(c_start, c_cond)`.")
        
    #     c_start, c_cond = c_past_and_cond

    #     model.eval()
    #     batch_size = c_start.shape[0]

    #     # --- ğŸ”´ 3. ä¿®æ”¹ï¼šé‡‡æ ·çš„èµ·ç‚¹ z æ˜¯ c_start (c_past) ---
    #     z = self.normer.norm(c_start) # å½’ä¸€åŒ– t=1 çš„ç‚¹

    #     t_vals = torch.linspace(1.0, 0.0, sample_steps + 1, device=device)

    #     for i in range(sample_steps):
    #         t = torch.full((z.size(0),), t_vals[i], device=device)
    #         r = torch.full((z.size(0),), t_vals[i + 1], device=device)

    #         t_ = rearrange(t, "b -> b 1 1 1 1").detach().clone()
    #         r_ = rearrange(r, "b -> b 1 1 1 1").detach().clone()

    #         # --- ğŸ”´ 4. ä¿®æ”¹ï¼šä½¿ç”¨ c_cond (c_rfdpic) ä½œä¸ºæ¡ä»¶ y ä¼ å…¥ ---
    #         v = model(z, t, r, c_cond)
    #         z = z - (t_-r_) * v

    #     z = self.normer.unnorm(z)
    #     return z
    
    @torch.no_grad()
    def sample_prediction(self, model, c_past_and_cond, sample_steps=5, device='cuda'):
        # ... (å‰åºæ£€æŸ¥ä¿æŒä¸å˜) ...
        c_start, c_cond = c_past_and_cond
        model.eval()
        
        z = torch.randn_like(c_start)
        
        # t ä» 1.0 (å™ªå£°/è¿‡å») -> 0.0 (å¹²å‡€/æœªæ¥)
        t_vals = torch.linspace(1.0, 0.0, sample_steps + 1, device=device)

        for i in range(sample_steps):
            t_curr = t_vals[i]
            t_next = t_vals[i + 1]
            
            t = torch.full((z.size(0),), t_curr, device=device)
            r = torch.full((z.size(0),), t_next, device=device)
            
            # --- ğŸ”´ æ ¸å¿ƒä¿®æ”¹: é‡‡æ ·æ—¶çš„è½¬æ¢ ---
            # 1. æ¨¡å‹é¢„æµ‹ x (å¹²å‡€æ•°æ®)
            x_pred = model(z, t, r, c_cond)
            
            # 2. è½¬æ¢ä¸ºé€Ÿåº¦ v = (z - x) / t
            # å¤„ç† t=0 çš„æƒ…å†µ (æœ€åä¸€å…ƒ)ï¼Œé˜²æ­¢é™¤é›¶
            if t_curr < 1e-5:
                # å¦‚æœå½“å‰å·²ç»æ˜¯ t=0 (ç†è®ºä¸Šå¾ªç¯æœ€åä¸€æ­¥æ˜¯åˆ°è¾¾0ï¼Œä¸æ˜¯ä»0å¼€å§‹)ï¼Œ
                # æˆ–è€…éå¸¸æ¥è¿‘0ï¼Œç›´æ¥è®¤ä¸ºå·²ç»åˆ°è¾¾ç›®æ ‡ã€‚
                # ä½†ç”±äºè¿™é‡Œæ˜¯ Euler æ­¥è¿› z -> z_nextï¼Œå¦‚æœåœ¨ t=0 å¤„è®¡ç®— v å¯èƒ½ä¼šä¸ç¨³å®šã€‚
                # åœ¨ Euler ç§¯åˆ†ä¸­ï¼šz_next = z + (t_next - t_curr) * v
                # ä»£å…¥ v = (z - x_pred) / t_curr
                # z_next = z + (t_next - t_curr) * (z - x_pred) / t_curr
                # å½“ t_curr å¾ˆå°æ—¶ï¼Œæ•°å€¼ä¸ç¨³å®šã€‚
                # ç­–ç•¥ï¼šClip t 
                denom = max(t_curr, 1e-3)
                v = (z - x_pred) / denom
            else:
                v = (z - x_pred) / t_curr
                
            t_ = rearrange(t, "b -> b 1 1 1 1")
            r_ = rearrange(r, "b -> b 1 1 1 1")
            
            # 3. æ›´æ–° z (Standard Euler step)
            # z_next = z + dt * v = z + (r - t) * v
            z = z + (r_ - t_) * v 

        z = self.normer.unnorm(z)
        return z