# videoMeanflow.py
import torch
import torch.nn.functional as F
from einops import rearrange
from functools import partial
import numpy as np


class Normalizer:
    # --- ä¿æŒä¸å˜ ---
    def __init__(self, mode='minmax', mean=None, std=None):
        assert mode in ['minmax', 'mean_std'], "mode must be 'minmax' or 'mean_std'"
        self.mode = mode

        if mode == 'mean_std':
            if mean is None or std is None:
                raise ValueError("mean and std must be provided for 'mean_std' mode")
            self.mean = torch.tensor(mean).view(1, 1, -1, 1, 1)
            self.std = torch.tensor(std).view(1, 1, -1, 1, 1)
        
    @classmethod
    def from_list(cls, config):
        mode, mean, std = config
        return cls(mode, mean, std)

    def norm(self, x):
        if self.mode == 'minmax':
            return x * 2 - 1
        elif self.mode == 'mean_std':
            return (x - self.mean.to(x.device)) / self.std.to(x.device)

    def unnorm(self, x):
        if self.mode == 'minmax':
            x = x.clip(-1, 1)
            return (x + 1) * 0.5
        elif self.mode == 'mean_std':
            return x * self.std.to(x.device) + self.mean.to(x.device)


def stopgrad(x):
    return x.detach()


def adaptive_l2_loss(error, gamma=0.5, c=1e-3):
    # --- ä¿æŒä¸å˜ ---
    delta_sq = torch.mean(error ** 2, dim=(1, 2, 3, 4), keepdim=False)
    p = 1.0 - gamma
    w = 1.0 / (delta_sq + c).pow(p)
    loss = delta_sq
    return (stopgrad(w) * loss).mean()


class MeanFlow:
    def __init__(
        self,
        channels=8,
        time_dim=6,
        height_dim=256,
        width_dim=256,
        normalizer=['minmax', None, None],
        # mean flow settings
        flow_ratio=0.50,
        # time distribution, mu, sigma
        time_dist=['lognorm', -0.4, 1.0],
        # --- ğŸ”´ ç§»é™¤æ‰€æœ‰ CFG ç›¸å…³å‚æ•° ---
        jvp_api='autograd',
    ):
        super().__init__()
        self.channels = channels
        self.time_dim = time_dim
        self.height_dim = height_dim
        self.width_dim = width_dim
        
        # --- ğŸ”´ ç§»é™¤äº† num_classes, use_cond ---
        # --- ğŸ”´ ç§»é™¤äº† cfg_ratio, cfg_scale, cfg_uncond ---

        self.normer = Normalizer.from_list(normalizer)
        self.flow_ratio = flow_ratio
        self.time_dist = time_dist
        self.jvp_api = jvp_api

        assert jvp_api in ['funtorch', 'autograd'], "jvp_api must be 'funtorch' or 'autograd'"
        if jvp_api == 'funtorch':
            self.jvp_fn = torch.func.jvp
            self.create_graph = False
        elif jvp_api == 'autograd':
            self.jvp_fn = torch.autograd.functional.jvp
            self.create_graph = True

    # sample_t_r (æ— ä¿®æ”¹)
    def sample_t_r(self, batch_size, device):
        if self.time_dist[0] == 'uniform':
            samples = np.random.rand(batch_size, 2).astype(np.float32)

        elif self.time_dist[0] == 'lognorm':
            mu, sigma = self.time_dist[-2], self.time_dist[-1]
            normal_samples = np.random.randn(batch_size, 2).astype(np.float32) * sigma + mu
            samples = 1 / (1 + np.exp(-normal_samples))  # Apply sigmoid

        t_np = np.maximum(samples[:, 0], samples[:, 1])
        r_np = np.minimum(samples[:, 0], samples[:, 1])

        num_selected = int(self.flow_ratio * batch_size)
        indices = np.random.permutation(batch_size)[:num_selected]
        r_np[indices] = t_np[indices]

        t = torch.tensor(t_np, device=device)
        r = torch.tensor(r_np, device=device)
        return t, r

    def loss(self, model, x, c=None): # x=x_future, c=c_past
        """
        ğŸ”´ æ ¸å¿ƒä¿®æ”¹ï¼š
        - e (t=1 çš„ç‚¹) ä¸å†æ˜¯å™ªå£°ï¼Œè€Œæ˜¯ c (c_past)
        - v (ç›®æ ‡é€Ÿåº¦) å˜ä¸º c - x
        - ç§»é™¤äº†æ‰€æœ‰ CFG é€»è¾‘
        """
        if c is None:
            raise ValueError("c (c_past) must be provided as the starting distribution (t=1)")
            
        # å‡è®¾ï¼šx_future (x) å’Œ c_past (c) å…·æœ‰å®Œå…¨ç›¸åŒçš„å½¢çŠ¶
        if x.shape != c.shape:
            raise ValueError(f"In this mode, x (x_future) and c (c_past) must have the same shape. "
                             f"Got x: {x.shape} and c: {c.shape}")
                             
        batch_size = x.shape[0]
        device = x.device

        t, r = self.sample_t_r(batch_size, device)
        t_ = rearrange(t, "b -> b 1 1 1 1").detach().clone()
        r_ = rearrange(r, "b -> b 1 1 1 1").detach().clone()

        # --- ğŸ”´ æ ¸å¿ƒä¿®æ”¹åœ¨è¿™é‡Œ ---
        # e æ˜¯ t=1 çš„åˆ†å¸ƒ (c_past)ï¼Œx æ˜¯ t=0 çš„åˆ†å¸ƒ (x_future)
        e = c # e æ˜¯ c_past
        
        # å½’ä¸€åŒ–ä¸¤ä¸ªç«¯ç‚¹
        x = self.normer.norm(x) # x (x_future) è¢«å½’ä¸€åŒ–åˆ° [-1, 1]
        e = self.normer.norm(e) # e (c_past) ä¹Ÿè¢«å½’ä¸€åŒ–åˆ° [-1, 1]
        
        # z æ˜¯ x å’Œ e ä¹‹é—´çš„æ’å€¼
        z = (1 - t_) * x + t_ * e
        
        # v æ˜¯ä» x åˆ° e çš„æ’å®šé€Ÿåº¦å‘é‡
        v = e - x
        # --- ä¿®æ”¹ç»“æŸ ---

        # --- ğŸ”´ ç§»é™¤æ‰€æœ‰ CFG é€»è¾‘ ---
        # v_hat ç°åœ¨å°±æ˜¯ v
        v_hat = v

        # forward pass
        # --- ğŸ”´ ä¿®æ”¹ï¼šæ¨¡å‹ä¸å†æ¥æ”¶ y=c_cond ---
        # model_partial = partial(model, y=c_cond) # <-- ç§»é™¤
        
        jvp_args = (
            # --- ğŸ”´ ä¿®æ”¹ï¼šç›´æ¥è°ƒç”¨ modelï¼Œä¸å¸¦ y ---
            lambda z, t, r: model(z, t, r),
            (z, t, r),
            (v_hat, torch.ones_like(t), torch.zeros_like(r)),
        )

        if self.create_graph:
            u, dudt = self.jvp_fn(*jvp_args, create_graph=True)
        else:
            u, dudt = self.jvp_fn(*jvp_args)

        u_tgt = v_hat - (t_ - r_) * dudt

        error = u - stopgrad(u_tgt)
        loss = adaptive_l2_loss(error)

        mse_val = (stopgrad(error) ** 2).mean()
        return loss, mse_val

    # 6. --- ğŸ”´ æ›¿æ¢é‡‡æ ·å‡½æ•° ---
    @torch.no_grad()
    def sample_prediction(self, model, c_past, sample_steps=5, device='cuda'):
        """
        ğŸ”´ æ ¸å¿ƒä¿®æ”¹ï¼š
        - é‡‡æ ·çš„èµ·ç‚¹ z ä¸å†æ˜¯é«˜æ–¯å™ªå£°ï¼Œè€Œæ˜¯å½’ä¸€åŒ–åçš„ c_past
        - æ¨¡å‹è°ƒç”¨ä¸å†ä¼ å…¥ y=c_past
        """
        model.eval()
        batch_size = c_past.shape[0]

        # --- ğŸ”´ æ ¸å¿ƒä¿®æ”¹åœ¨è¿™é‡Œ ---
        # é‡‡æ ·çš„èµ·ç‚¹ (t=1) æ˜¯ c_past
        # æˆ‘ä»¬å¿…é¡»åƒè®­ç»ƒæ—¶ä¸€æ ·å¯¹å…¶è¿›è¡Œå½’ä¸€åŒ–
        z = self.normer.norm(c_past)
        # --- ä¿®æ”¹ç»“æŸ ---

        t_vals = torch.linspace(1.0, 0.0, sample_steps + 1, device=device)

        for i in range(sample_steps):
            t = torch.full((z.size(0),), t_vals[i], device=device)
            r = torch.full((z.size(0),), t_vals[i + 1], device=device)

            t_ = rearrange(t, "b -> b 1 1 1 1").detach().clone()
            r_ = rearrange(r, "b -> b 1 1 1 1").detach().clone()

            # --- ğŸ”´ æ ¸å¿ƒä¿®æ”¹åœ¨è¿™é‡Œ ---
            # æ¨¡å‹ä¸å†éœ€è¦æ¡ä»¶ c_pastï¼Œå› ä¸ºå®ƒå·²ç»æ˜¯æµçš„ä¸€éƒ¨åˆ†
            v = model(z, t, r) # <-- ç§»é™¤äº† c_past
            # --- ä¿®æ”¹ç»“æŸ ---
            
            z = z - (t_-r_) * v

        # æœ€åä¸€æ­¥ unnorm ä¿æŒä¸å˜
        z = self.normer.unnorm(z)
        return z